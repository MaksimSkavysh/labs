{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!** Данную лабораторную нужно выполнять на **Python 3.6+**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Работа с метаклассами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.1 (0.6 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте метакласс **BoundedMeta**, который контролирует количество созданных объектов классов, которые имеют данный метакласс. Допустимое количество объектов задайте параметром (по умолчанию 1).\n",
    "\n",
    "В случае превышения бросайте исключение **TypeError**. Eсли значение параметра - **None**, то ограничений нету.\n",
    "\n",
    "Другими словами, у класса **C** с метаклассом **BoundedMeta** должно быть создано не более 2 экземпляров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C(metaclass=BoundedMeta, max_instance_count=2):\n",
    "    pass\n",
    "\n",
    "c1 = C()\n",
    "c2 = C()\n",
    "\n",
    "try:\n",
    "    c3 = C()\n",
    "except TypeError:\n",
    "    print('everything works fine!')\n",
    "else:\n",
    "    print('something goes wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.2 (0.6 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс **BoundedBase**, в котором определен абстрактный classmethod get_max_instance_count, возвращающий максимальное количество экзмепляров, которые можно создать.\n",
    "\n",
    "Не допускайте ***создания*** объекта, если данное значение превышено - бросайте исключение **TypeError**. Значение, равное **None** - без ограничений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(BoundedBase):\n",
    "    @classmethod\n",
    "    def get_max_instance_count(cls):\n",
    "        return 1\n",
    "    \n",
    "d1 = D()\n",
    "\n",
    "try:\n",
    "    d2 = D()\n",
    "except TypeError:\n",
    "    print('everything works fine!')\n",
    "else:\n",
    "    print('something goes wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Работа с NumPy и SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В области машинного обучения одним из самых популярных методов бинарной классификации (предсказываем один из двух классов, $+1$ или $-1$ для каждого объекта) является логистическая регрессия. Она выводится из метода максимального правдоподобия, который приводит к следующей задаче оптимизации:\n",
    "\n",
    "$$ L(w, X, y) = \\frac1{N}\\sum_{i = 0}^{N} log (1 + exp(-y_ix_i^Tw)) + \\frac{C}{2} ||w||^2 \\longrightarrow \\min_w$$\n",
    "$$X \\in R^{N \\times M}, x \\in R^{M}, w \\in R^{M}, y \\in \\{-1, 1\\}^N$$\n",
    "\n",
    "Здесь $X$ - матрица объекты-признаки для обучающей выборки (по строкам объекты, по столбцам признаки), а $y$ - вектор ответов. Коэффициент $C$, вообще говоря, нужно подбирать отдельно, поскольку разные его значения приводят к разным решениям задачи оптимизации. Но в этой задаче положим $\\mathbf{C = 10^{-3}}$\n",
    "\n",
    "Когда мы решили задачу оптимизации (нашли $w$), мы принимаем решение о том, к какому классу относится объект по правилу $y(x) = sign(x^Tw)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестирования правильности вычисления сгенерируем аргументы небольшого размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size, features_count = 25, 10\n",
    "w = np.random.random(features_count)\n",
    "X, y = np.random.random((sample_size, features_count)), 2 * (np.random.randint(0, 2, sample_size) - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.1 (0.2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = np.hstack((X, y[:, np.newaxis]))\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного поработаем с ndarray. Получите из массива XY обратно X и y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.2 (0.2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрограммируйте вычисление функции L, используйте только матричные операции (внутри не должно быть циклов).\n",
    "\n",
    "**Замечание**: Нигде в промежуточных вычислениях не стоит вычислять значение $\\exp(−y_ix^Tw)$, иначе может произойти переполнение. Вместо этого следует напрямую вычислять необходимые величины с помощью специализированных для этого функций: `np.logaddexp` для `ln(1 + exp(·))` и `sp.special.expit` для `1/(1 + exp(-(·)))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(w, X, y):\n",
    "    \"\"\"\n",
    "        logistic(w, X, y) вычисляет функцию качества лог регрессии L(w, X, y)\n",
    "        \n",
    "        w: np.array размера (M,)\n",
    "        X: np.array размера (N, M)\n",
    "        y: np.array размера (M,)\n",
    "        \n",
    "        funcw: np.float \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3.1 (0.3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите градиент функции $\\nabla_w L(w, X, y)$, запишите в терминах матричных операций.\n",
    "\n",
    "Эффективно запрограммируйте вычисление градиента (опять же, только матричные операции!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_grad(w, X, y):\n",
    "    '''\n",
    "        logistic_grad(w, X, y) вычисляет градиент функции качества лог регрессии dL(w, X, y)/dw\n",
    "        \n",
    "        w: np.array размера (M,)\n",
    "        X: np.array размера (N, M)\n",
    "        y: np.array размера (M,)\n",
    "        \n",
    "        gradw: np.array размера (M,)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(logistic_grad(w, X, y).shape == w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3.2 (0.3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень часто при подсчёте градиента допускаются ошибки, проверьте правильность реализации подсчёта градиента с помощью конечных разностей. \n",
    "\n",
    "$$[\\nabla f(x)]_i \\approx \\frac{f(x + \\varepsilon \\cdot e_i) - f(x)}{\\varepsilon}~~~~$$\n",
    "\n",
    "где $e_i = (0, ... , 0, 1, 0, ..., 0)$ - i-й базисный орт, $\\epsilon \\approx 10^{-8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_error(a, b): \n",
    "    return np.max(np.abs(a - b))\n",
    "\n",
    "\n",
    "def grad_finite_diff(func, x, eps=1e-8):\n",
    "    \"\"\"\n",
    "        w: np.array размера (M,)\n",
    "        func: скалярная функция от векторного аргумента w, func(w) =  число\n",
    "        eps: np.float константа для проверки градиента\n",
    "        \n",
    "        dnum: np.array размера (M,), численно посчитанный градиент\n",
    "    \"\"\"\n",
    "    x, fval, dnum = x.astype(np.float64), func(x), np.zeros_like(x)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_grad = logistic_grad(w, X, y)\n",
    "num_grad = grad_finite_diff(lambda w: logistic(w, X, y), w)\n",
    "\n",
    "err = max_error(mat_grad, num_grad)\n",
    "print('err = ', err, 'ok' if err < 1e-6 else 'ошибка очень большая!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.4.1 (0.4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач оптимизации очень удобно использовать гессиан.\n",
    "\n",
    "Вычислите гессиан для функции L, запишите ответ в терминах матричных операций. Эффективно запрограммируйте вычисление гессиана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_hess(w, X, y):\n",
    "    \"\"\"\n",
    "        logistic_hess(w, X, y) вычисляет гессиан функции качества лог регрессии dL(w, X, y)/dw\n",
    "        \n",
    "        w: np.array размера (M,)\n",
    "        X: np.array размера (N, M)\n",
    "        y: np.array размера (M,)\n",
    "        \n",
    "        hessw: np.array размера (M, M)\n",
    "    \"\"\"\n",
    "    #hessw = # Гессиан dL/dw_iw_j\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(logistic_hess(w, X, y).shape == (w.shape[0], w.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.4.2 (0.4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим правильность реализации подсчёта гессиана.\n",
    "\n",
    "Для гессиана проверка выглядит похожим образом\n",
    "\n",
    "$$[\\nabla^2 f(x)]_{ij} \\approx \\frac{f(x + \\varepsilon \\cdot e_i + \\varepsilon \\cdot e_j) -f(x + \\varepsilon \\cdot e_i) - f(x + \\varepsilon \\cdot e_j)+ f(x)}{\\varepsilon^2}~~~~~~~~~~~~~~~~~~~~~$$\n",
    "\n",
    "где $e_i = (0, ... , 0, 1, 0, ..., 0)$ - i-й базисный орт, $\\varepsilon \\approx 10^{-4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hess_finite_diff(func, w, eps=1e-4):\n",
    "    '''\n",
    "        w: np.array размера (M,)\n",
    "        func: скалярная функция от векторного аргумента w, func(w) =  число\n",
    "        eps: np.float константа для проверки градиента\n",
    "        \n",
    "        dnum: np.array размера (M,), численно посчитанный градиент\n",
    "    '''\n",
    "    w, fval, dnum = w.astype(np.float64), func(w).astype(np.float64), np.zeros((w.size, w.size), dtype=np.float64)\n",
    "    #dnum = # Вычислите численный гессиан d func/dw_iw_j для всех i, j\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_grad = logistic_hess(w, X, y)\n",
    "num_grad = hess_finite_diff(lambda w: logistic(w, X, y), w)\n",
    "\n",
    "err = max_error(mat_grad, num_grad)\n",
    "\n",
    "print('err = ', err)\n",
    "print('ok' if max_error(mat_grad, num_grad) < 1e-4 else 'ошибка очень большая!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
